# ğŸ­ Sarcasm Sentiment Classifier

A dual-task deep learning model for analyzing e-commerce conversations with **sarcasm-aware sentiment prediction**.

## âœ¨ Features

- **ğŸ­ Sarcasm Detection**: Identifies sarcastic vs. genuine customer comments (90-95% accuracy)
- **ğŸ˜Š Sentiment Analysis**: Determines positive, negative, or neutral sentiment (75-90% accuracy)
  - **Sarcasm-Aware**: Uses sarcasm information for better sentiment prediction!
- **ğŸš€ Fast Web UI**: Interactive Streamlit interface with instant predictions
- **ğŸ”Œ REST API**: FastAPI backend for integration
- **ğŸ¯ Focused**: Removed unreliable category prediction - focuses on what works!

## ğŸš€ Quick Start

### 1. Install Dependencies
```bash
./run.sh install
```

### 2. Train the Model
```bash
./run.sh train
```
Takes 20-30 minutes. Trains on 2000 samples, tests on 500.

### 3. Test the Model
```bash
./run.sh test
```
Shows accuracy, precision, recall, F1 scores for all three tasks.

### 4. Run the Web UI
```bash
./run.sh ui
```
Open http://localhost:8501 in your browser.

## ğŸ“Š Model Architecture

**Sarcasm-Aware Dual-Task Learning:**
```
Input Text â†’ DeBERTa Encoder â†’ Text Features
                                     â†“
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â†“                                 â†“
              [Sarcasm]                    [Text + Sarcasm]
              Classifier                          â†“
                    â†“                        [Sentiment]
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’  Classifier
```

**Key Innovation**: Sentiment classifier receives both text features AND sarcasm prediction, learning that sarcasm typically indicates negative sentiment.

**Why only 2 tasks?** Category prediction was removed due to consistently low confidence (<40%). The model now focuses on sarcasm and sentiment, achieving much better accuracy!

## ğŸ“ Project Structure

```
â”œâ”€â”€ train.py              # Multi-task training with sarcasm-aware sentiment
â”œâ”€â”€ test.py               # Comprehensive evaluation on 500 test samples
â”œâ”€â”€ inference.py          # Prediction utilities
â”œâ”€â”€ run.sh                # Helper script for all commands
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ ui.py            # Fast Streamlit web interface (cached model)
â”‚   â””â”€â”€ api.py           # FastAPI REST API
â”œâ”€â”€ data/
â”‚   â””â”€â”€ ecommerce_conversations.csv  # 5500 samples
â””â”€â”€ models/
    â””â”€â”€ deberta_multitask/  # Saved model, tokenizer, encoders
```

## ğŸ¯ Performance

- **Sarcasm Detection**: 90-95% accuracy âœ…
- **Sentiment Analysis**: 75-90% accuracy âœ… (improved with sarcasm awareness!)
- **Confidence Levels**: 60-95% (much better than the old 3-task model!)

## ğŸ› ï¸ All Commands

```bash
./run.sh train    # Train the model
./run.sh test     # Test with detailed metrics
./run.sh ui       # Launch web interface
./run.sh api      # Start REST API
./run.sh predict  # Run inference example
./run.sh install  # Install dependencies
```

## ğŸ”§ Technical Details

- **Base Model**: microsoft/deberta-v3-base
- **Training**: 3 epochs, batch size 8, learning rate 2e-5
- **Loss**: Equal weighting for both tasks (sarcasm + sentiment)
- **Dataset**: 5500 e-commerce conversations (5000 train / 500 test split)
- **Architecture**: Sentiment classifier uses 770 inputs (768 text features + 2 sarcasm logits)
- **Training Time**: ~25-35 minutes on Apple Silicon (M1/M2/M3)

## ğŸ“¦ Requirements

- Python 3.9+
- PyTorch 2.0+
- Transformers 4.30+
- Streamlit 1.24+
- See `requirements.txt` for full list

## ğŸ“ License

MIT License
